---
title: '分布式与并行机器学习资源列表（持续更新）'
date: 2020-1-1
permalink: /blog-posts/2020/1/1/分布式与并行机器学习资源列表（持续更新）
tags:
  - distributed
  - machine learning
  - paper
---

我知道的近些年分布式与并行机器学习各大顶会论文

(NIPS 2012) Large Scale Distributed Deep Networks

(CoRR 2018) Horovod: Fast and Easy Distributed Deep Learning in TensorFlow

(ATC 2017) Poseidon: An Efficient Communication Architecture for Distributed Deep Learning on GPU Clusters

(EuroSys 2016) GeePS: Scalable Deep Learning on Distributed GPUs
with A GPU-specialized Parameter Server

(SOSP 2019) A Generic Communication Scheduler for Distributed DNN Training Acceleration

(NSDI 2019) Tiresias: A GPU Cluster Manager for Distributed Deep Learning

(SysML 2019) Tictac: Accelerating Distributed Deep Learning with
Communication Scheduling

(OSDI 2018) Gandiva: Introspective Cluster Scheduling for Deep Learning

(NeurIPS 2018) BML A High-performance , Low-cost Gradient Synchronization Algorithm for DML Training

(NetAI 2018) HiPS Hierarchical Parameter Synchronization in Large-Scale Distributed Machine Learning - Geng et al

(Infocom 2019) Impact of Network Topology on the Performance of

(Arxiv 2019) Blink: Fast and Generic Collectives for Distributed ML

(Arxiv 2018) GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism

(Arxiv 2019) Optimization for deep learning: theory and algorithms







